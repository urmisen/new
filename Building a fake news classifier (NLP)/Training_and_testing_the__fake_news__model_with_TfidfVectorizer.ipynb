{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_and_testing_the_\"fake news\"_model_with TfidfVectorizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLtpmi3Sfln"
      },
      "source": [
        "###  Training and testing the \"fake news\" model with TfidfVectorizer\n",
        "Now that you have evaluated the model using the CountVectorizer, you'll do the same using the TfidfVectorizer with a Naive Bayes model.\n",
        "\n",
        "The training and test sets have been created, and tfidf_vectorizer, tfidf_train, and tfidf_test have been computed. Additionally, MultinomialNB and metrics have been imported from, respectively, sklearn.naive_bayes and sklearn.\n",
        "\n",
        "* Instantiate a MultinomialNB classifier called nb_classifier.\n",
        "* Fit the classifier to the training data.\n",
        "* Compute the predicted tags for the test data.\n",
        "* Calculate and print the accuracy score of the classifier.\n",
        "* Compute the confusion matrix. As in the previous exercise, specify the keyword argument labels=['FAKE', 'REAL'] so that the resulting confusion matrix is easier to read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTwG8ZQ9SabR"
      },
      "source": [
        "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "nb_classifier.fit(tfidf_train, y_train)\n",
        "\n",
        "# Create the predicted tags: pred\n",
        "pred = nb_classifier.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score: score\n",
        "score = metrics.accuracy_score(y_test,pred)\n",
        "print(score)\n",
        "\n",
        "# Calculate the confusion matrix: cm\n",
        "cm = metrics.confusion_matrix(y_test,pred,labels=['FAKE', 'REAL'])\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaRhwmAFVmc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdMd_mUvFVSr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}