{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_and_testing_the_\"fake news\"_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLtpmi3Sfln"
      },
      "source": [
        "###  Training and testing the \"fake news\" model with CountVectorizer\n",
        "Now it's your turn to train the \"fake news\" model using the features you identified and extracted. In this first exercise you'll train and test a Naive Bayes model using the CountVectorizer data.\n",
        "\n",
        "The training and test sets have been created, and count_vectorizer, count_train, and count_test have been computed. \n",
        "\n",
        "* Import the metrics module from sklearn and MultinomialNB from sklearn.naive_bayes.\n",
        "* Instantiate a MultinomialNB classifier called nb_classifier.\n",
        "* Fit the classifier to the training data.\n",
        "* Compute the predicted tags for the test data.\n",
        "* Calculate and print the accuracy score of the classifier.\n",
        "* Compute the confusion matrix. To make it easier to read, specify the keyword argument labels=['FAKE', 'REAL']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTwG8ZQ9SabR"
      },
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "nb_classifier.fit(count_train, y_train)\n",
        "\n",
        "# Create the predicted tags: pred\n",
        "pred = nb_classifier.predict(count_test)\n",
        "\n",
        "# Calculate the accuracy score: score\n",
        "score = metrics.accuracy_score(y_test,pred)\n",
        "print(score)\n",
        "\n",
        "# Calculate the confusion matrix: cm\n",
        "cm = metrics.confusion_matrix(y_test,pred,labels=['FAKE', 'REAL'])\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouaRhwmAFVmc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdMd_mUvFVSr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}